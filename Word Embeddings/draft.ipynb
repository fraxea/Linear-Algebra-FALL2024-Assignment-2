{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "Welcome to the second notebook of this assignment! Word embeddings are numerical representations of words. We can represent words as vectors and maintain their meaning. There are various ways of finding vecotrs for words, equivalently, word embeddings. We explore some of these techniques in this notebook.\n",
    "\n",
    "## Tabel of Contents\n",
    "\n",
    "- 1- GloVe: Global Vectors for Word Representation\n",
    "  - 1.1- Exploring word vectors\n",
    "  - 1.2- Visualizing in 2-D\n",
    "- 2- Evaluation\n",
    "  - 2.1- Cosine similarity\n",
    "  - 2.2- A little test set\n",
    "- 3- Learn embeddings\n",
    "  - 3.1- Co-occurences\n",
    "  - 3-2. SVD\n",
    "- 4- Sentiment Analysis of MDB Movie Reviews\n",
    "  - 4.1- Dataset\n",
    "  - 4.2- Model\n",
    "  - 4.3- Train\n",
    "  - 4.4- Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- GloVe: Global Vectors for Word Representation\n",
    "\n",
    "### 1.1- Exploring word vectors\n",
    "\n",
    "What is the number of words in vocabulary? What is the dimensionality of word vectors?\n",
    "\n",
    "|         | man   | woman | king  | queen | apple | orange |\n",
    "| ---     | ---   | ---   |   --- | ---   | ---   |  ---   |\n",
    "| gender  | -0.99 | 1     | -0.95 | 0.97  | u     | 0.01   |\n",
    "| royalty | 0.01  | 0.02  | 0.93  | 0.95  | -0.01 | 0.00   |\n",
    "| fruit   | 0.03  | x     | y     | z     | 0.94  | v      |\n",
    "\n",
    "What would be the values of $x, y, z, u, v$ and why?\n",
    "\n",
    "man - woman = king - queen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2- Visualizing in 2-D\n",
    "\n",
    "tall -> taller -> tallest, big -> bigger -> biggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the quality of word vectors, we should look at the similarity of word vectors that are semantically similar, for example word *France* is similar to *Italy*, so their word vectors should be similar. One common metric to measure the distance between word vectors is the **cosine similarity**. The cosine similarity between two words $w_x$ and $w_y$ is defined as\n",
    "$$\n",
    "cos(w_x, w_y) = \\frac{w_x^Tw_y}{||w_x|| ||w_y||}\n",
    "$$\n",
    ", where $||.||$ is the $l_2$ norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One evaluation approach that was introduced in [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781) is to consider two pairs of words that have the same type of relationship, for example, *big - bigger* and *small - smaller*. Each two pairs can be viewed as a question: ”What is the word that is similar to small in the same sense as bigger is similar to big?”.\n",
    "\n",
    "Interestingly, these questions can be answered by doing basic algebraic operations on the word vectors. First we compute $$x = w_{bigger}-w_{big}+w_{small}$$, and then search through all possible word vectors to find the closest one to $x$. In this notebook we use cosine similarity to measure closeness. So the problem can be written as $$ w^{*} = \\argmax_{w} cos(w, w_{bigger}-w_{big}+w_{small}) $$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [\n",
    "    [\"Paris\", \"France\", \"Toronto\", \"Canada\"],\n",
    "    [\"Australia\", \"dollar\", \"Japan\", \"yen\"],\n",
    "    [\"Chicago\", \"Illinois\", \"Stockton\", \"California\"],\n",
    "    [\"brother\", \"sister\", \"father\", \"mother\"],\n",
    "    [\"apparent\", \"apparently\", \"rapid\", \"rapidly\"],\n",
    "    [\"possibly\", \"impossibly\", \"ethical\", \"ethically\"],\n",
    "    [\"great\", \"greater\", \"tough\", \"tougher\"],\n",
    "    [\"easy\", \"easiest\", \"lucky\", \"luckiest\"],\n",
    "    [\"think\", \"thinking\", \"read\", \"reading\"],\n",
    "    [\"Switzerland\", \"Swiss\", \"Turkey\", \"Turkish\"],\n",
    "    [\"walking\", \"walked\", \"swimming\", \"swam\"],\n",
    "    [\"mouse\", \"mice\", \"dollar\", \"dollars\"],\n",
    "    [\"work\", \"works\", \"speak\", \"speaks\"],\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
